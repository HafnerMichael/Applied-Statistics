{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import norm, gaussian_kde, multivariate_normal\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from KDEpy import TreeKDE, FFTKDE"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) Explore the data using suitable methods and tools."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_KDE_2D.csv')\n",
    "data_array = data.to_numpy()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Data Describe:\\r\\n\", data.describe())\n",
    "print(\"\\r\\nData Head:\\r\\n\", data.head())\n",
    "\n",
    "xval = np.arange(len(data.index))\n",
    "plt.scatter(data['X'], data['Y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find an appropriate k for KMeans clustering: Method seen [towardsdatascience](https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "km = KMeans(random_state=42)\n",
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    "\n",
    "visualizer.fit(data)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### No clear elbow point can be found! Let´s try the silhouette method. (Observing datapoints by eye: k should be around 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15,8))\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    '''\n",
    "    Create KMeans instances for different number of clusters\n",
    "    '''\n",
    "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(i, 2)\n",
    "    '''\n",
    "    Create SilhouetteVisualizer instance with KMeans instance\n",
    "    Fit the visualizer\n",
    "    '''\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(data)\n",
    "\n",
    "\"\"\"\n",
    "The following conditions should be checked to pick the right ‘K’ using the Silhouette plots:\n",
    "\n",
    "1.  For a particular K, all the clusters should have a Silhouette score more than the average score of the dataset (represented by a red dotted line).\n",
    "    The x-axis represents the Silhouette score. (Hold for all cluster!)\n",
    "2.  There should not be wide fluctuations in the size of the clusters. The width of the clusters represents the number of data points.\n",
    "    For K = 2, the best fit is shown, since other ks vary in size\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# So take k=2\n",
    "\n",
    "kmean = KMeans(n_clusters=2).fit(data)\n",
    "labels = kmean.predict(data)\n",
    "data['label'] = labels\n",
    "plt.scatter(data['X'], data['Y'], cmap='viridis', c=labels)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Group the data to generate a meaningful histogram of the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "# Generate 2D histogram (H contains the count)\n",
    "H, xedges, yedges = np.histogram2d(x, y, bins=10)\n",
    "\n",
    "# Create 3D plot\n",
    "X, Y = np.meshgrid(xedges, yedges)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Count')\n",
    "ax.set_title('Histogram')\n",
    "ax.plot_surface(X[:-1, :-1], Y[:-1, :-1],H, cmap='viridis')\n",
    "ax.view_init(elev=45, azim=320)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c) Try to fit a normal distribution into the data. Plot the surface and contours of the fitted normal distribution on top of the data points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov = np.cov(data_array, bias=True)\n",
    "cov"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov0 = np.diag([1.,1.])\n",
    "data0 = data[data[\"label\"]==0]\n",
    "xvar0 = np.var(data0.iloc[:, 0])\n",
    "yvar0 = np.var(data0.iloc[:, 1])\n",
    "cov0[0][0] = xvar0\n",
    "cov0[1][1] = yvar0\n",
    "\n",
    "cov1 = np.diag([1.,1.])\n",
    "data1 = data[data[\"label\"]==1]\n",
    "xvar1 = np.var(data1.iloc[:, 0])\n",
    "yvar1 = np.var(data1.iloc[:, 1])\n",
    "cov1[0][0] = xvar1\n",
    "cov1[1][1] = yvar1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meanx0 = np.mean(data0[\"X\"])\n",
    "meany0 = np.mean(data0[\"Y\"])\n",
    "\n",
    "meanx1 = np.mean(data1[\"X\"])\n",
    "meany1 = np.mean(data1[\"Y\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rv0 = multivariate_normal([meanx0, meany0], cov0)\n",
    "pos0 = np.dstack((X, Y))\n",
    "z0 = rv0.pdf(pos0)\n",
    "\n",
    "rv1 = multivariate_normal([meanx1, meany1], cov1)\n",
    "pos1 = np.dstack((X, Y))\n",
    "z1 = rv1.pdf(pos1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('Datapoints and their normal distribution')\n",
    "z = z0+z1\n",
    "ax.scatter(data0[\"X\"],data0[\"Y\"],c=\"red\")\n",
    "ax.scatter(data1[\"X\"],data1[\"Y\"],c=\"blue\")\n",
    "ax.plot_surface(X, Y,z, cmap='viridis', alpha=0.2)\n",
    "\n",
    "\n",
    "ax.view_init(elev=45, azim=320)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## d) Multivariate kernel density estimation: Put a kernel (Gaussian, box, triangular) on top of every data point. Discuss the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the points\n",
    "plt.figure(figsize=(14, 3));\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Data points')\n",
    "plt.scatter(data['X'], data['Y'], marker='.', c='r', label='Data')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Count')\n",
    "ax.set_title('Data points with kernel functions')\n",
    "\n",
    "for i in range (3,6):\n",
    "    ax.scatter(data.iloc[i]['X'],data.iloc[i]['Y'],c='red')\n",
    "\n",
    "    tree_kde = TreeKDE(kernel='gaussian')\n",
    "    # fit the model on the 2D data\n",
    "    tree_kde.fit(data=np.array(data.iloc[i][['X', 'Y']]).reshape(1,2))\n",
    "\n",
    "    # evaluate the density estimate at a set of points\n",
    "    grid_points = np.column_stack((X.ravel(), Y.ravel()))\n",
    "    density = tree_kde.evaluate(grid_points)\n",
    "    ax.plot_surface(X, Y,density.reshape(11,11), alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# create TreeKDE object\n",
    "tree_kde = TreeKDE(kernel='gaussian')\n",
    "\n",
    "# fit the model on the 2D data\n",
    "tree_kde.fit(data=np.array(data[['X', 'Y']]))\n",
    "\n",
    "grid_points = np.column_stack((X.ravel(), Y.ravel()))\n",
    "density = tree_kde.evaluate(grid_points)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Count')\n",
    "ax.set_title('Data points with kernel functions summed')\n",
    "ax.scatter(data0[\"X\"],data0[\"Y\"],c=\"red\")\n",
    "ax.scatter(data1[\"X\"],data1[\"Y\"],c=\"blue\")\n",
    "ax.plot_surface(X, Y,density.reshape(11,11), alpha=0.5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## e) Vary the parameters of the kernels (bandwidth, weights, ...) used in (d) and combine them to get a KDE.\n",
    "# Gaussian Kernel - Play with bandwidth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for bw in [0.1, 0.8, 10]:\n",
    "\n",
    "    kde = FFTKDE(kernel='gaussian', bw=bw)\n",
    "\n",
    "    # fit the model on the 2D data\n",
    "    kde.fit(data=np.array(data[['X', 'Y']]))\n",
    "\n",
    "    grid_points = np.column_stack((X.ravel(), Y.ravel()))\n",
    "    density = kde.evaluate(grid_points)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Count')\n",
    "    ax.set_title('BW = {}'.format(bw))\n",
    "    ax.scatter(data0[\"X\"],data0[\"Y\"],c=\"red\")\n",
    "    ax.scatter(data1[\"X\"],data1[\"Y\"],c=\"blue\")\n",
    "    ax.plot_surface(X, Y,density.reshape(11,11), alpha=0.5, label=bw)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Kernel - Play with weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_array = data[['X', 'Y']].to_numpy()\n",
    "weights = np.linspace(0.1,50, 100)\n",
    "\n",
    "kde = FFTKDE(kernel='gaussian')\n",
    "\n",
    "# fit the model on the 2D data\n",
    "kde.fit(data=data_array, weights=weights)\n",
    "\n",
    "grid_points = np.column_stack((X.ravel(), Y.ravel()))\n",
    "density = kde.evaluate(grid_points)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Count')\n",
    "ax.set_title('BW = {}'.format(bw))\n",
    "ax.scatter(weights,c=\"red\")\n",
    "ax.plot_surface(X, Y,density.reshape(11,11), alpha=0.5, label=bw)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
